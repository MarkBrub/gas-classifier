{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group images from /data/Thermal Camera Images by class into folders\n",
    "\n",
    "classes = [\"NoGas\", \"Perfume\", \"Smoke\", \"Mixture\"]\n",
    "IMAGE_LENGTH = 480\n",
    "IMAGE_WIDTH = 640\n",
    "\n",
    "REORGANIZE_DATA = False\n",
    "\n",
    "if REORGANIZE_DATA:\n",
    "    for c in classes:\n",
    "        if not os.path.exists(\"data/Thermal Camera Images/\" + c):\n",
    "            os.makedirs(\"data/Thermal Camera Images/\" + c)\n",
    "\n",
    "    # move images into folders\n",
    "    # images follow the pattern: \"#_class.png\"\n",
    "\n",
    "    # get all .png files in the directory\n",
    "    files = os.listdir(\"data/Thermal Camera Images\")\n",
    "    png_files = [f for f in files if f.endswith(\".png\")]\n",
    "\n",
    "    # move images into folders\n",
    "    for f in png_files:\n",
    "        # get the class of the image\n",
    "        class_name = f.split(\"_\")[1]\n",
    "        # remove the .png extension\n",
    "        class_name = class_name.split(\".\")[0]\n",
    "        # move the image into the corresponding folder\n",
    "        os.rename(\"data/Thermal Camera Images/\" + f, \"data/Thermal Camera Images/\" + class_name + \"/\" + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(tf.data.Dataset):\n",
    "    def __init__(self, data, use_sensors=True, use_images=True):\n",
    "        # filepaths = data['filepath']\n",
    "        self.images = data['filepath'].values\n",
    "        # MQ2 MQ3 MQ5 MQ6 MQ7 MQ8 MQ135\n",
    "        self.sensor_data = data[['MQ2', 'MQ3', 'MQ5', 'MQ6', 'MQ7', 'MQ8', 'MQ135']].values\n",
    "        # Gas values\n",
    "        self.classes = data['Gas'].values\n",
    "        # Gas one-hot encoded\n",
    "        cat = OneHotEncoder()\n",
    "        self.labels = cat.fit_transform(self.classes.reshape(-1, 1)).toarray()\n",
    "        self.use_sensors = use_sensors\n",
    "        self.use_images = use_images\n",
    "\n",
    "        if not use_sensors and not use_images:\n",
    "            raise ValueError(\"Both use_sensors and use_images cannot be False\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.images[idx]\n",
    "        image = tf.io.read_file(filepath)\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        \n",
    "        # normalize image\n",
    "        image = image / 255.0\n",
    "\n",
    "        sensor_data = self.sensor_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.use_sensors and self.use_images:\n",
    "            return (image, sensor_data), label\n",
    "        elif self.use_sensors:\n",
    "            return sensor_data, label\n",
    "        elif self.use_images:\n",
    "            return image, label\n",
    "        \n",
    "    def _inputs(self):\n",
    "        if self.use_images and self.use_sensors:\n",
    "            return (tf.TensorSpec(shape=(None, IMAGE_LENGTH, IMAGE_WIDTH, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(None, 7), dtype=tf.float32))\n",
    "        elif self.use_images:\n",
    "            return tf.TensorSpec(shape=(None, IMAGE_LENGTH, IMAGE_WIDTH, 3), dtype=tf.float32)\n",
    "        elif self.use_sensors:\n",
    "            return tf.TensorSpec(shape=(None, 7), dtype=tf.float32)\n",
    "        else:\n",
    "            raise ValueError(\"At least one of use_images or use_sensors must be True\")\n",
    "        \n",
    "    def element_spec(self):\n",
    "        if self.use_images and self.use_sensors:\n",
    "            return ((tf.TensorSpec(shape=(IMAGE_LENGTH, IMAGE_WIDTH, 3), dtype=tf.float32),\n",
    "                     tf.TensorSpec(shape=(7,), dtype=tf.float32)),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    "        elif self.use_images:\n",
    "            return (tf.TensorSpec(shape=(IMAGE_LENGTH, IMAGE_WIDTH, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    "        elif self.use_sensors:\n",
    "            return (tf.TensorSpec(shape=(7,), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(), dtype=tf.int32))\n",
    "        else:\n",
    "            raise ValueError(\"At least one of use_images or use_sensors must be True\")\n",
    "        \n",
    "    def get_path(self, idx):\n",
    "        return self.images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MQ2</th>\n",
       "      <th>MQ3</th>\n",
       "      <th>MQ5</th>\n",
       "      <th>MQ6</th>\n",
       "      <th>MQ7</th>\n",
       "      <th>MQ8</th>\n",
       "      <th>MQ135</th>\n",
       "      <th>Gas</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>515</td>\n",
       "      <td>377</td>\n",
       "      <td>338</td>\n",
       "      <td>666</td>\n",
       "      <td>451</td>\n",
       "      <td>416</td>\n",
       "      <td>NoGas</td>\n",
       "      <td>data/Thermal Camera Images/NoGas/0_NoGas.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555</td>\n",
       "      <td>516</td>\n",
       "      <td>377</td>\n",
       "      <td>339</td>\n",
       "      <td>666</td>\n",
       "      <td>451</td>\n",
       "      <td>416</td>\n",
       "      <td>NoGas</td>\n",
       "      <td>data/Thermal Camera Images/NoGas/1_NoGas.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>556</td>\n",
       "      <td>517</td>\n",
       "      <td>376</td>\n",
       "      <td>337</td>\n",
       "      <td>666</td>\n",
       "      <td>451</td>\n",
       "      <td>416</td>\n",
       "      <td>NoGas</td>\n",
       "      <td>data/Thermal Camera Images/NoGas/2_NoGas.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>556</td>\n",
       "      <td>516</td>\n",
       "      <td>376</td>\n",
       "      <td>336</td>\n",
       "      <td>665</td>\n",
       "      <td>451</td>\n",
       "      <td>416</td>\n",
       "      <td>NoGas</td>\n",
       "      <td>data/Thermal Camera Images/NoGas/3_NoGas.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>556</td>\n",
       "      <td>516</td>\n",
       "      <td>376</td>\n",
       "      <td>337</td>\n",
       "      <td>665</td>\n",
       "      <td>451</td>\n",
       "      <td>416</td>\n",
       "      <td>NoGas</td>\n",
       "      <td>data/Thermal Camera Images/NoGas/4_NoGas.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MQ2  MQ3  MQ5  MQ6  MQ7  MQ8  MQ135    Gas  \\\n",
       "0  555  515  377  338  666  451    416  NoGas   \n",
       "1  555  516  377  339  666  451    416  NoGas   \n",
       "2  556  517  376  337  666  451    416  NoGas   \n",
       "3  556  516  376  336  665  451    416  NoGas   \n",
       "4  556  516  376  337  665  451    416  NoGas   \n",
       "\n",
       "                                       filepath  \n",
       "0  data/Thermal Camera Images/NoGas/0_NoGas.png  \n",
       "1  data/Thermal Camera Images/NoGas/1_NoGas.png  \n",
       "2  data/Thermal Camera Images/NoGas/2_NoGas.png  \n",
       "3  data/Thermal Camera Images/NoGas/3_NoGas.png  \n",
       "4  data/Thermal Camera Images/NoGas/4_NoGas.png  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load sensor data from data/Gas Sensors Measurements/Gas_Sensor_Measurements.csv\n",
    "file_data = pd.read_csv(\"data/Gas Sensors Measurements/Gas_Sensors_Measurements.csv\")\n",
    "\n",
    "# drop the first column\n",
    "file_data = file_data.drop(columns=[\"Serial Number\"])\n",
    "\n",
    "# rename Corrosponding Image Name to filename\n",
    "file_data = file_data.rename(columns={\"Corresponding Image Name\": \"filepath\"})\n",
    "\n",
    "# change the image names from \"#_class\" to \"/data/Thermal Camera Images/class/#_class.png\"\n",
    "file_data[\"filepath\"] = file_data[\"filepath\"].apply(lambda x: \"data/Thermal Camera Images/\" + x.split(\"_\")[1] + \"/\" + x + \".png\")\n",
    "\n",
    "file_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480, 3)\n",
      "[740 530 389 383 556 549 451]\n",
      "Class: Smoke label: [0. 0. 1. 0.]\n",
      "\n",
      "(640, 480, 3)\n",
      "[588 368 305 346 581 566 297]\n",
      "Class: Mixture label: [0. 0. 0. 1.]\n",
      "\n",
      "(640, 480, 3)\n",
      "[767 532 450 457 641 719 489]\n",
      "Class: Smoke label: [0. 0. 1. 0.]\n",
      "\n",
      "(640, 480, 3)\n",
      "[771 533 423 419 550 624 487]\n",
      "Class: Perfume label: [0. 1. 0. 0.]\n",
      "\n",
      "(640, 480, 3)\n",
      "[772 530 432 437 596 671 485]\n",
      "Class: Perfume label: [0. 1. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = MultimodalDataset(file_data, use_sensors=True, use_images=True)\n",
    "\n",
    "# get 10 random values from the dataset\n",
    "for i in range(5):\n",
    "    data, label = dataset[np.random.randint(0, len(dataset))]\n",
    "    print(data[0].shape)\n",
    "    print(data[1])\n",
    "    # get the class name from the one-hot encoded label\n",
    "    print(f'Class: {classes[np.argmax(label)]} label: {label}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 14:04:26.132033: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 278921216 exceeds 10% of free system memory.\n",
      "2023-03-09 14:04:26.523957: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 278921216 exceeds 10% of free system memory.\n",
      "2023-03-09 14:04:27.183637: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 278921216 exceeds 10% of free system memory.\n",
      "/home/markbrub/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 14:04:29.594853: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 278921216 exceeds 10% of free system memory.\n",
      "2023-03-09 14:04:30.414959: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 278921216 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# create an image only dataset from the first 100 images\n",
    "image_dataset = MultimodalDataset(file_data[:100], use_sensors=False, use_images=True)\n",
    "\n",
    "# create a simple CNN\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(480, 640, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(dataset, epochs=10, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
